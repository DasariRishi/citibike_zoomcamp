# citibike_zoomcamp
# Citibike Data Pipeline with Kestra, BigQuery, dbt & Looker Studio

## ğŸ“Œ Overview
This project automates the extraction, transformation, and visualization of **Citi Bike** trip data. The pipeline utilizes **Kestra** for data orchestration, **Google Cloud Storage & BigQuery** for storage and processing, **dbt** for transformations, and **Looker Studio** for dashboard visualization.

## ğŸš€ Features
- **Automated Data Ingestion:** Kestra fetches data monthly from [CitiBike Trip Data](https://s3.amazonaws.com/tripdata/index.html).
- **Cloud Storage:** Extracted data is stored in **Google Cloud Storage (GCS)**.
- **BigQuery Staging & Processing:** The data is loaded into **BigQuery**, where it is staged and merged into the main `citibike_tripdata` table.
- **Transformations with dbt:** The raw data is cleaned and structured for analysis.
- **Dashboard in Looker Studio:** The transformed data is visualized in an interactive dashboard.

## ğŸ“ Repository Structure
```
ğŸ“‚ citibike-dbt-pipeline
â”œâ”€â”€ ğŸ“‚ models             # dbt models for data transformation
â”‚   â”œâ”€â”€ core             # Core transformation models
â”‚   â”œâ”€â”€ staging          # Staging models
â”œâ”€â”€ ğŸ“‚ tests             # dbt tests and validations
â”œâ”€â”€ ğŸ“‚ macros            # dbt macros
â”œâ”€â”€ ğŸ“‚ seeds             # Seed data (if any)
â”œâ”€â”€ ğŸ“‚ scripts           # Python scripts for additional processing
â”œâ”€â”€ ğŸ“‚ kestra            # Kestra YAML workflow files
â”œâ”€â”€ project_dbt.yml      # dbt project configuration
â”œâ”€â”€ README.md            # Project documentation
â””â”€â”€ requirements.txt     # Python dependencies
```

## ğŸ” Explore the Repository
- **Kestra Workflow:** Defines the extraction and load jobs.
- **dbt Models:** Contains transformation logic for cleaning and structuring data.
- **BigQuery Tables:** Stores both raw and transformed data.
- **Looker Dashboard:** Connects to BigQuery for visualization.

## ğŸ”„ Project Workflow
1. **Kestra extracts Citi Bike trip data** and loads it into **Google Cloud Storage**.
2. Data is **staged in BigQuery**.
3. The **staging table is merged into `citibike_tripdata`**.
4. **dbt transforms the data** into a structured format.
5. The **transformed data is stored back in BigQuery**.
6. **Looker Studio dashboard** provides insights into trip trends, popular stations, and more.

## ğŸ”„ Architecture
![project_Architecture_diagram](images/345.jpg)

## ğŸ› ï¸ Technologies Used
- **Kestra** â€“ Data Orchestration
- **Google Cloud Platform (GCP)** â€“ Storage & BigQuery
- **dbt (Data Build Tool)** â€“ Data Transformation
- **Looker Studio** â€“ Dashboard & Visualization
- **Docker** â€“ Containerized Workflow Execution

## ğŸ“ Languages
- **SQL** (BigQuery SQL for transformations)
- **Python** (Data extraction & automation)

## ğŸ“š Libraries
- `dbt-bigquery`
- `pandas`
- `google-cloud-bigquery`
- `requests`

## ğŸ”§ Tools
- **Jupyter Notebook**: Interactive data exploration and analysis.
- **GitHub**: Version control and collaboration.

## âœ… Prerequisites
- Python **3.8 or higher**
- **Jupyter Notebook** (for local analysis)
- **Google Cloud SDK** (for BigQuery & GCS access)
- **Docker** (for running Kestra workflows)

## âš™ï¸ Installation
```bash
# Clone the repository
git clone https://github.com/yourusername/citibike-dbt-pipeline.git
cd citibike-dbt-pipeline

# Install dependencies
pip install -r requirements.txt

# Set up dbt profiles.yml (if needed)
mkdir -p ~/.dbt
nano ~/.dbt/profiles.yml

# Run dbt models
dbt run

# Validate the transformations
dbt test
```

## ğŸ“Š Looker Dashboard
The dashboard provides insights into:
- **Trip Frequency**
- **Popular Stations**
- **Monthly Trends**
- **User Type Analysis (Members vs. Casual Users)**

ğŸ”— **[View the Looker Dashboard](#)**(https://lookerstudio.google.com/reporting/2bbae005-985f-42d0-86b9-49bf53debeac)

---
### ğŸ“© Feel free to contribute or raise issues!
